There has been a lot of talk around the new kid on the block - Perplexity.ai. 
I was curious to understand more about the tool and decided to test it with a plain vanilla Finance and Sales dataset.

[1]Steps followed
1. Upload the dataset [in .xlsx format]
2. Provide specific and clear prompts without ambiguity
3. Refine and revise the prompts as needed.

[2]Prompts Provided
1. 'I am a Finance Manager. I need to know the Life to Date Sales, units sold, Profit and Profit % of 'Montana' throughout all the segments. Analyze this report and use tables, visuals and commentaries to provide an explanation. Keep the visuals neat and crisp, making it easy for a senior business stakeholder to interpret and take quick decisions.'

2. 'Which country has the least manufacturing costs for Montana?'

3. 'Thanks. Now, how do I reduce my manufacturing costs? I am unable to shift my production to Germany due to logistical constraints. Other than the options in the attached file, can you provide other lucrative locations worldwide, which have a low manufacturing cost?' 

- This prompt was provided to test the reasoning capabilities of the LLM beyond the scope of the dataset :,>

4. 'Provide a line chart detailing the total sales of the company(by product) in the United States, which have a Profit > $10,000'

[3]Observations
1.The tool did pretty well until Prompt 4, where it was unable to provide the data visualization in the format I was looking for. 
2. It is easy to get carried away by the speed of response, yet it is necessary to verify if the data provided is correct, similar to a 2 step authentication.

Either way - it was clear to me that running an LLM and expecting it to always be correct may not be the right approach. We need to have the element of 'human-in-the-loop' prior to sharing data with senior stakeholders and decision makers.
